# CoTracker: It is Better to Track Together

## 0 Abstract

视频的运动预测（Motion Estimation）方法有：
1. 共同地估计视频中所有点瞬时运动的光流法。
2. 独立地跟踪视频中个别点，且这些点能够在有遮挡的情况下继续跟踪。

独立地跟踪点会忽略点与点之间可能存在的强相关性，例如，它们可能属于同一物体，这可能会降低性能。

Transformer 通过专门的注意层模拟不同时刻点与点之间的关联。Transformer 会迭代地更新多条轨迹的估计。我们工程了一个训练循环展开，可以以滑动窗口的方式应用于非常长的视频。它可以联合跟踪一个或多个点，并支持随时添加新的跟踪点。

## 1 Introduction

运动预测的问题描述：给定一个或多个由三维场景的某些物理点的投影而成的二维点，目标是找到同一物理点在视频的所有其他帧中的位置。

**光流的目标是估计视频帧内所有点的速度。这种估计是针对所有点共同进行的，但是运动只在一个无穷小的距离内进行预测。跟踪的目标是在较长的时间段内估计点的运动。出于效率和建模简化的考虑，跟踪方法通常关注稀疏选择的点，并将它们视为在统计上是独立的。**

我们认为，*考虑被跟踪点之间的相关性可以显著提高跟踪的准确性。*

我们的神经网络以视频和若干个起始跟踪位置作为输入，并输出完整的跟踪轨迹。该网络的工作方式是首先采用跟踪的初始、近似版本，然后逐步优化它们以更好地匹配视频的内容。跟踪的初始化是相对简单的：给定一个跟踪点或跟踪片段，可以通过假设该点保持静止来初始化跟踪的其余部分。通过这种方式，可以从视频的任何点开始初始化轨迹，甚至可以从以滑动窗口方式操作的跟踪器自身的输出开始初始化。同一架构可以无缝支持所有这些情况。

网络本身是一个在 2D 标记网格上运行的 Transformer：第一个网格维度表示时间，第二个维度表示被跟踪的点集合。通过适当的自注意力操作符，Transformer 可以在窗口的持续时间内将每个跟踪点视为一个整体，并且可以在跟踪点之间交换信息，利用它们之间的相关性。

## 2 Related Work

