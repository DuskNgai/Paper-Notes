# Hierarchical Variational Autoencoder

记号同 [3 Variational Auto-encoder](../3%20Variational%20Autoencoder.md)。

---

![](images/hvae.png)

Hierarchical Variational Autoencoder (HVAE)，特别是 Markovian Hierarchical Variational Autoencoder (MHVAE)，将多个 VAE 串联起来。除了第一个 VAE 的潜空间是从数据空间编码而来，其他每个 VAE 的潜空间都是从之前一个 VAE 的潜空间编码而来。因此，联合分布写成：
$$
\begin{aligned}
p(\mathbf{x} \mid \mathbf{z}_{1:T}; \theta) &= p(\mathbf{z}_T; \theta) p(\mathbf{x} \mid \mathbf{z}_1; \theta) \prod_{t = 2}^{T} p(\mathbf{z}_{t - 1} \mid \mathbf{z}_{t}; \theta) \\
q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi) &= q(\mathbf{z}_1 \mid \mathbf{x}; \phi) \prod_{t = 2}^{T} q(\mathbf{z}_t \mid \mathbf{z}_{t - 1}; \phi)
\end{aligned}
$$
对应的 ELBO 为：
$$
\begin{aligned}
\log p(\mathbf{x}; \theta) &= \log \int p(\mathbf{x}, \mathbf{z}_{1:T}; \theta) \mathrm{d} \mathbf{z}_{1:T} \\
&= \log \int \frac{p(\mathbf{x}, \mathbf{z}_{1:T}; \theta) q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi)}{q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi)} \mathrm{d} \mathbf{z}_{1:T} \\
&= \log \mathbb{E}_{q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi)} \left[\frac{p(\mathbf{x}, \mathbf{z}_{1:T}; \theta)}{q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi)} \right] \\
&\geq \mathbb{E}_{q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi)} \log \left[\frac{p(\mathbf{x}, \mathbf{z}_{1:T}; \theta)}{q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi)} \right]
\end{aligned}
$$
其中：
$$
\begin{aligned}
\mathrm{ELBO}(q, \mathbf{x}; \theta, \phi) &= \mathbb{E}_{q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi)} \log \left[\frac{p(\mathbf{x}, \mathbf{z}_{1:T}; \theta)}{q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi)} \right] \\
&= \mathbb{E}_{q(\mathbf{z}_{1:T} \mid \mathbf{x}; \phi)} \log \left[\frac{p(\mathbf{z}_T; \theta) p(\mathbf{x} \mid \mathbf{z}_1; \theta) \prod_{t = 2}^{T} p(\mathbf{z}_{t - 1} \mid \mathbf{z}_{t}; \theta)}{q(\mathbf{z}_1 \mid \mathbf{x}; \phi) \prod_{t = 2}^{T} q(\mathbf{z}_t \mid \mathbf{z}_{t - 1}; \phi)} \right]
\end{aligned}
$$

## VAE Automatic Classification (Optional)

我们可以在隐空间上对数据进行分类。将原本的 $\mathbf{z}$ 拆分为连续特征表征 $\mathbf{z}$ 和离散聚类标签 $y$，则联合分布表示为：
$$
\begin{aligned}
&\quad\ \ \mathrm{KL}\left[q(\mathbf{x}, \mathbf{z}, y; \phi) \parallel p(\mathbf{x}, \mathbf{z}, y; \theta)\right] \\
&= \mathbb{E}_{\mathbf{x}, \mathbf{z}, y \sim q(\mathbf{x}, \mathbf{z}, y; \phi)} \left[\log \frac{q(\mathbf{x}, \mathbf{z}, y; \phi)}{p(\mathbf{x}, \mathbf{z}, y; \theta)}\right] \\
&= \iint \sum_{y} q(\mathbf{x}, \mathbf{z}, y; \phi) \log \frac{q(\mathbf{x}, \mathbf{z}, y; \phi)}{p(\mathbf{x}, \mathbf{z}, y; \theta)} \mathrm{d} \mathbf{x} \mathrm{d} \mathbf{z} \\
&= \iint \sum_{y} q(\mathbf{z}, y \mid \mathbf{x}; \phi) p(\mathbf{x}) \log \frac{q(\mathbf{z}, y \mid \mathbf{x}; \phi) p(\mathbf{x})}{p(\mathbf{x} \mid \mathbf{z}, y; \theta) p(\mathbf{z}, y; \theta)} \mathrm{d} \mathbf{x} \mathrm{d} \mathbf{z}
\end{aligned}
$$
为了进一步细化损失函数计算，我们需要假设一些变量关系。这里按照 MHVAE 的方案，假设 $\mathbf{z}$ 只与 $\mathbf{x}$ 有关，$y$ 只与 $\mathbf{z}$ 有关。因此有：
$$
\begin{aligned}
q(\mathbf{z}, y \mid \mathbf{x}; \phi) &= q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi) \\
p(\mathbf{x} \mid \mathbf{z}, y; \theta) &= p(\mathbf{x} \mid \mathbf{z}; \theta) \\
p(\mathbf{z}, y; \theta) &= p(\mathbf{z} \mid y; \theta) p(y)
\end{aligned}
$$
带入得到：
$$
\begin{aligned}
&\quad\ \ \mathrm{KL}\left[q(\mathbf{x}, \mathbf{z}, y; \phi) \parallel p(\mathbf{x}, \mathbf{z}, y; \theta)\right] \\
&= \iint \sum_{y} q(\mathbf{z}, y \mid \mathbf{x}; \phi) p(\mathbf{x}) \log \frac{q(\mathbf{z}, y \mid \mathbf{x}; \phi) p(\mathbf{x})}{p(\mathbf{x} \mid \mathbf{z}, y; \theta) p(\mathbf{z}, y; \theta)} \mathrm{d} \mathbf{x} \mathrm{d} \mathbf{z} \\
&= \iint \sum_{y} q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi) p(\mathbf{x}) \log \frac{q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi) p(\mathbf{x})}{p(\mathbf{x} \mid \mathbf{z}; \theta) p(\mathbf{z} \mid y; \theta) p(y)} \mathrm{d} \mathbf{x} \mathrm{d} \mathbf{z} \\
&= \underbrace{\iint \sum_{y} q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi) p(\mathbf{x}) \log p(\mathbf{x}) \mathrm{d} \mathbf{x} \mathrm{d} \mathbf{z}}_{\text{Constant}} \\
&+ \iint \sum_{y} q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi) p(\mathbf{x}) \log \frac{q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi)}{p(\mathbf{x} \mid \mathbf{z}; \theta) p(\mathbf{z} \mid y; \theta) p(y)} \mathrm{d} \mathbf{x} \mathrm{d} \mathbf{z} \\
&= \text{Constant} + \mathbb{E}_{\mathbf{x} \sim p(\mathbf{x})} \left[\int \sum_{y} q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi) \log \frac{q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi)}{p(\mathbf{x} \mid \mathbf{z}; \theta) p(\mathbf{z} \mid y; \theta) p(y)} \mathrm{d} \mathbf{z}\right]
\end{aligned}
$$
对于第二项，计算方法如下：
$$
\begin{aligned}
&\quad\ \ \int \sum_{y} q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi) \log \frac{q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi)}{p(\mathbf{x} \mid \mathbf{z}; \theta) p(\mathbf{z} \mid y; \theta) p(y)} \mathrm{d} \mathbf{z} \\
&= \int \sum_{y} q(y \mid \mathbf{z}; \phi) q(\mathbf{z} \mid \mathbf{x}; \phi) \log \frac{q(\mathbf{z} \mid \mathbf{x}; \phi)}{p(\mathbf{z} \mid y; \theta)} \mathrm{d} \mathbf{z} \\
&\quad + \int q(\mathbf{z} \mid \mathbf{x}; \phi) \mathrm{KL}[q(y \mid \mathbf{z}; \phi) \parallel p(y)] \mathrm{d} \mathbf{z} \\
&\quad - \int q(\mathbf{z} \mid \mathbf{x}; \phi) \log p(\mathbf{x} \mid \mathbf{z}; \theta) \mathrm{d} \mathbf{z} \\
&= \mathbb{E}_{\mathbf{z} \sim q(\mathbf{z} \mid \mathbf{x}; \phi)} \left[\mathbb{E}_{y \sim q(y \mid \mathbf{z}; \phi)} \left[\log \frac{q(\mathbf{z} \mid \mathbf{x}; \phi)}{p(\mathbf{z} \mid y; \theta)} + \mathrm{KL}[q(y \mid \mathbf{z}; \phi) \parallel p(y)] - \log p(\mathbf{x} \mid \mathbf{z}; \theta) \right] \right]
\end{aligned}
$$
为了方便计算，我们需要规定分布的形式。我们假设 $q(\mathbf{z} \mid \mathbf{x}; \phi)$ 是 $Z$ 维多元 Gaussian 分布，$q(y \mid \mathbf{z}; \phi)$ 是定义在 $Y$ 个取值上的分类分布，$p(y)$ 是定义在 $Y$ 个取值上的均匀分类分布，$p(\mathbf{z} \mid y; \theta)$ 是 $Z$ 维多元 Gaussian 分布，$p(\mathbf{x} \mid \mathbf{z}; \theta)$ 是与输入相同维度的多元 Gaussian 分布。因此解析计算相关项，注意第一个和第二个等式是等价的：
$$
\begin{aligned}
&\quad\ \ \mathbb{E}_{\mathbf{z} \sim q(\mathbf{z} \mid \mathbf{x}; \phi)} \left[\mathbb{E}_{y \sim q(y \mid \mathbf{z}; \phi)} \left[\log \frac{q(\mathbf{z} \mid \mathbf{x}; \phi)}{p(\mathbf{z} \mid y; \theta)} \right] \right] \\
&= \frac{1}{2} \mathbb{E}_{\mathbf{z} \sim q(\mathbf{z} \mid \mathbf{x}; \phi)} \left[\mathbb{E}_{y \sim q(y \mid \mathbf{z}; \phi)} \left[\sum_{i=1}^{Z} \log \boldsymbol{\sigma}^{2}_{i}(y) - \sum_{i=1}^{Z} \log \boldsymbol{\sigma}^{2}_{i}(\mathbf{x}) + \left\|\frac{\mathbf{z} - \boldsymbol{\mu}(y)}{\boldsymbol{\sigma}(y)} \right\|^{2} - \left\|\frac{\mathbf{z} - \boldsymbol{\mu}(\mathbf{x})}{\boldsymbol{\sigma}(\mathbf{x})} \right\|^{2} \right] \right] \\
&= \frac{1}{2} \mathbb{E}_{\mathbf{z} \sim q(\mathbf{z} \mid \mathbf{x}; \phi)} \left[\sum_{y} q(y \mid \mathbf{z}; \phi) \left[\sum_{i=1}^{Z} \log \boldsymbol{\sigma}^{2}_{i}(y) - \sum_{i=1}^{Z} \log \boldsymbol{\sigma}^{2}_{i}(\mathbf{x}) + \left\|\frac{\mathbf{z} - \boldsymbol{\mu}(y)}{\boldsymbol{\sigma}(y)} \right\|^{2} - \|\boldsymbol{\epsilon} \|^{2} \right] \right]
\end{aligned}
$$
$$
\begin{aligned}
&\quad\ \ \mathbb{E}_{y \sim q(y \mid \mathbf{z}; \phi)} \left[\mathrm{KL}[q(\mathbf{z} \mid \mathbf{x}; \phi) \parallel p(\mathbf{z} \mid y; \theta)] \right] \\
&= \frac{1}{2} \mathbb{E}_{y \sim q(y \mid \mathbf{z}; \phi)} \left[\sum_{i=1}^{Z} \left(\log \boldsymbol{\sigma}^{2}_{i}(y) - \log \boldsymbol{\sigma}^{2}_{i}(\mathbf{x}) + \frac{\boldsymbol{\sigma}^{2}_{i}(\mathbf{x})}{\boldsymbol{\sigma}^{2}_{i}(y)} + \frac{(\boldsymbol{\mu}_{i}(\mathbf{x}) - \boldsymbol{\mu}_{i}(y))^2}{\boldsymbol{\sigma}_{i}^2(y)} - 1 \right) \right]
\end{aligned}
$$
$$
\begin{aligned}
\mathrm{KL}[q(y \mid \mathbf{z}; \phi) \parallel p(y)] &= \sum_{k=1}^{Y} a_{k}(\mathbf{z}) \log a_{k}(\mathbf{z}) + \log Y \\
\log p(\mathbf{x} \mid \mathbf{z}; \theta) &= -\frac{1}{2} \left\|\frac{\mathbf{x} - \mu(\mathbf{z})}{\sigma(\mathbf{z})} \right\|^2 - \frac{n}{2} \log 2\pi - \frac{1}{2} \log \sigma^2(\mathbf{z})
\end{aligned}
$$
前向过程为：

1. **隐变量后验估计**  
    编码器 $q(\mathbf{z} \mid \mathbf{x}; \phi)$ 接收维度为 $[B, X]$ 的输入数据，输出两个参数向量：
    - 隐变量均值 $\boldsymbol{\mu}(\mathbf{x}) \in \mathbb{R}^{B \times Z}$
    - 隐变量对数方差 $\log \boldsymbol{\sigma}^2(\mathbf{x}) \in \mathbb{R}^{B \times Z}$
    
2. **重参数化采样**  
    通过随机变换生成隐变量样本：  
    $$
    \mathbf{z} = \boldsymbol{\epsilon} \odot \exp\left(\frac{1}{2}\log\boldsymbol{\sigma}^{2}(\mathbf{x})\right) + \boldsymbol{\mu}(\mathbf{x})
    $$
    其中 $\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})$ 为高斯噪声，输出 $\mathbf{z} \in \mathbb{R}^{B \times Z}$
    
3. **类别分布推断**  
    分类器 $q(y \mid \mathbf{z}; \phi)$ 接收隐变量样本，输出类别概率分布：
    $$
    \boldsymbol{\alpha}(y) \in \mathbb{R}^{B \times Y}
    $$
    并计算与类别先验 $p(y)$ 的 KL 散度 $\mathop{\mathrm{KL}}[q(y \mid \mathbf{z}) \mid p(y)] \in \mathbb{R}^{B}$
    
4. **条件先验匹配**  
    根据类别维度 $Y$ 选择两种实现策略：
    
    - **蒙特卡洛采样策略**（适用于高维 $Y$）：
        - 从 $\boldsymbol{\alpha}(y)$ 采样类别标签 $\hat{y} \in \mathbb{R}^{B}$
        - 条件先验 $p(\mathbf{z} \mid \hat{y}; \theta)$ 输出参数 $(\boldsymbol{\mu}(\hat{y}), \boldsymbol{\sigma}(\hat{y})) \in \mathbb{R}^{B \times Z}$
        - 计算 KL 散度 $\mathop{\mathrm{KL}}[q(\mathbf{z} \mid \mathbf{x}) \mid p(\mathbf{z}\mid\hat{y})] \in \mathbb{R}^{B}$
        - 优势：计算效率高；劣势：收敛速度慢

    - **解析期望策略**（适用于低维 $Y$）：
        - 条件先验输出完整参数集 $(\boldsymbol{\mu}(y), \boldsymbol{\sigma}(y)) \in \mathbb{R}^{Y \times Z}$
        - 计算逐类别 KL 散度 $\mathop{\mathrm{KL}}[q(\mathbf{z}\mid\mathbf{x}) \mid p(\mathbf{z}\mid y)] \in \mathbb{R}^{B \times Y}$
        - 加权：$\mathbb{E}_{y \sim q}[\mathop{\mathrm{KL}}] = \sum_y \alpha(y) \mathop{\mathrm{KL}}(q \mid p) \in \mathbb{R}^{B}$
        - 优势：梯度估计精确；劣势：计算复杂度 $O(B \times Y)$

5. **数据重构**  
    解码器 $p(\mathbf{x} \mid \mathbf{z}; \theta)$ 接收隐变量样本，输出重构数据 $\hat{\mathbf{x}} \in \mathbb{R}^{B \times X}$，并计算重构误差 $\mathcal{L}_{\text{recon}} = \|\mathbf{x} - \hat{\mathbf{x}}\|^2 \in \mathbb{R}^{B}$